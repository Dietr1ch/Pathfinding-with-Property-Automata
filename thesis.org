# #+TITLE: Don't use org-mode title, it inserts unwanted \maketitle
#+AUTHOR: Dietrich Arnaldo Daroch González
#+DATE: December, 2016
#+LANGUAGE: en


# Setup
# -----
# Using LaTeX_CLASS requires additional setup!
#+LaTeX_CLASS: puc
#+LaTeX_CLASS_OPTIONS: [12pt,reqno,oneside]

# Packages
#+LaTeX_HEADER: \input{setup.tex}  % pucthesis setup (should be part of the LaTeX class!
#+LaTeX_HEADER: \usepackage[spanish,english]{babel}

# microtype (xelatex)
#+LaTeX_HEADER: \usepackage[final,factor=1100,stretch=10,shrink=10]{microtype}
# #+LaTeX_HEADER: \usepackage[activate={true,nocompatibility},final,tracking=true,kerning=true,spacing=true,factor=1100,stretch=10,shrink=10]{microtype}


#+SEQ_TODO: TODO | REVIEW DONE

#+OPTIONS: toc:nil
#+OPTIONS: tasks:t
#+OPTIONS: tags:nil
#+OPTIONS: d:nil
#+OPTIONS: skip:nil ^:nil timestamp:nil
#+STARTUP: overview

# Annoyances
# ----------
# „Quotes“

* Header                                                            :ignore:
#+begin_export LaTeX
\title[Evaluating Navigational RDF Queries]{Evaluating Navigational RDF Queries
	over the Web}

\address{Escuela de Ingenier\'ia\\
				 Pontificia Universidad Cat\'olica de Chile\\
				 Vicu\~na Mackenna 4860\\
				 Santiago, Chile\\
				 {\it Tel.\/} : 56 (2) 354-2000}
\email{Dietrich.Daroch@gmail.com}
%
\facultyto    {the School of Engineering}
\department   {}
\faculty      {Faculty of Engineering}
\degree       {Master of Science in Engineering}
\advisor      {Jorge Baier A.}
\committeememberA {Juan L. Reutter D.}
%\committeememberB {Committee Member B (Optional)}
\guestmemberA {Jorge P\'erez R.}
%\guestmemberB {Guest Committee Member B (Optional)}
\ogrsmember   {Juan Siding B.}  % TODO: change
\subject      {Engineering}
\date         {Diciembre 2016}
\copyrightname{Dietrich Daroch}
\copyrightyear{MMXVI}

\dedication {
To everyone
}

\NoChapterPageNumber
\pagenumbering{roman}
\maketitle
#+end_export

* Acknowledgements                                                  :ignore:
#+begin_export LaTeX
\selectlanguage{english}
\chapter*{Acknowledgements}

\cleardoublepage
#+end_export

* Tables                                                            :ignore:
#+begin_export LaTeX
\tableofcontents
\listoftables
\listoffigures
\cleardoublepage % In double-sided printing style makes the next page
#+end_export

* Abstract                                                          :ignore:
#+begin_export LaTeX
\selectlanguage{english}
\chapter*{Abstract}
\label{ch:abstract}
This works presents a novel reduction from \emph{Property Path Computation} to
\emph{Heuristic Search}, which enables to solve queries in a more efficient way
than the previously known reduction to \emph{Uninformed Search}.
The new reduction enables to use years of reaserch on Heuristic Search made by
the Artificial Intelligence community to solve \emph{Property Paths} over
\emph{Linked Data} more efficiently.
Besides the reduction, optimizations and implementation details are reviewed.


% Keywords
\vfill
{\bf Keywords:} \parbox[t]{.75\textwidth}{
	RDF, Semantic Web, Property Paths, Graph Databases
}
#+end_export

#+begin_export LaTeX
\chapter*{Resumen}
\label{ch:resumen}
\selectlanguage{spanish}
Este trabajo presenta una reducción nueva desde \emph{Property Path Computation} a
\emph{Búsqueda Heurística}, la cuál permite resolver consultas de manera más
eficiente que la anteriormente conocida reducción a \emph{Búsqueda Ciega}.
Esta nueva reducción permite aprovechar años de investigación en Búsqueda por
parte de la comunidad de Inteligencia Artificial para resolver consultas sobre
\emph{Property Paths} en \emph{Linked Data} de forma más eficiente.
Además de la reducción, se estudian optimizaciones y detalles de implementación.

% Keywords
\vfill
{\bf Palabras Claves:} \parbox[t]{.75\textwidth}{
	RDF, Web Semántica, Property Paths, Bases de Datos de Grafos
}


\selectlanguage{english}
#+end_export


* Setup                                                             :ignore:
#+begin_export LaTeX
\cleardoublepage
\pagenumbering{arabic}
#+end_export



* TODO Introduction
** TODO Background

People indirectly uses databases many times a day without noticing it.
Databases are key to manage information in many systems, which store information
ranging from instant messaging systems, email and documents to media and banking.
Today, that information is likely to be stored in tables obeying schemas
carefully tailored for each application.
This makes linking data across multiple applications hard, if not impossible.

To overcome the lack of connectivity of the stored data, the World Wide Web
Consortium (W3C) proposed to use the \citeA{RDF} as their recommended model to
shape and share data.

Linking data is not only interesting because it's hard to do, but mostly because
it offers new data to enhance applications.\cite{BaierDRV16}.

Today databases are used internally by many applications and systems

Long ago efforts to understand text were made, but today not all information
lies on plain text, or tree hierarchies. Techniques and machinery that appeared
then are not directly useful when working with Graphs.


** TODO Contribution
Essentially this works provides an algorithm to compute /Property Paths/ by
navigating that it's more efficient than the previously existing ones.

The algorithm is accompanied by proof of it's efficiency, as well as an
experimental evaluation that provides explicit evidence along with   the
contribution is


** TODO Outline
Section \ref{sec:Preliminaries} presents some background in Graphs and Automata,
as well as a definitions for the Semantic Web Search Problems, including
Heuristic Search.


* Preliminaries
#+begin_export latex
\label{sec:Preliminaries}
#+end_export

This chapter serves as a common basis for the following work. Definitions given
are slightly different and more general than the usual ones, all in order to
ease upcoming definitions.

The chapter is as brief as possible, but it's accompanied by examples on the appendix.


** Math
*** REVIEW Predicates
		CLOSED: [2016-12-15 Thu 11:45]
Intuitively, predicates are functions that filter or select elements from some
collection.

#+LATEX: \begin{definition}[Predicate]
/Predicates/ are functions mapping some space $X$ into the /Booleans/, which is
the set\nbsp{}$\set{ \top, \bot }$.
The set of all predicates over $X$ is denoted by $\Pred{X}$.
#+LATEX: \end{definition}

When some element is mapped to $\top$, we say that it is /accepted/ by the predicate.
A predicate $P$ is called /(positively) invertible/ if it is possible to compute
a set\nbsp{}$P^{-1}$ that holds all the elements accepted by $P$.
We say that $P$ is /finitely invertible/ when $P^{-1}$ is finite, and call $P$
/partially invertible/ if any nonempty subset of $P^{-1}$ can be computed.

As a notation abuse, we allow to cast subsets $Y \subset X$ to a predicate over $X$
that only accepts the elements of $Y$.

*** REVIEW Graphs
		CLOSED: [2016-12-15 Thu 11:45]
Intuitively, a Graph is a collection of objects with information about how those
objects are related.

#+LATEX: \begin{definition}[Graph]
Given a set $V$, a /Graph/ is a pair /vertices/ and /edges/, $(V, E)$, where $E$
is a collection of elements from $V^2$.
#+LATEX: \end{definition}
$E$ is usually a set, but when it allows duplication, the /Graph/ is called a
/Multi-Graph/ as multiple, distinguishable edges can join the same pair of vertices.

#+LATEX: \begin{definition}[Labeled Graph]
The relation given by $E$ can be detailed by using a set of labels $\Sigma$ and
a function $l\colon E \to \Sigma$ that assigns labels to each edge.

With this in mind, we define a /Labeled Graph/ as the tuple $(V, E, \Sigma, l)$.
We say that a Labeled Graph is /self-labeled/ when $\Sigma=V$.
#+LATEX: \end{definition}

It's easy to find examples that use graphs, for example consider $V$ as a set of
people, and $E$ as arcs that depict relations between the people. To explain
each relation from $E$, the label $\Sigma$ can contain, for example, /friends/,
/best-friends/, /ex-girlfriend/ can be used.

** Automata
An /Automaton/ is a Labeled Graph extended to describe sequences.

Automatons are thought as representations of machines, so different terminology
is used. Vertices are used to denote internal /States/ of a machine, and
edges show which /Transitions/ of states are possible. Transitions require
specific input to happen, which is specified by the label of each transition.

The sequences described are the inputs used to transition from a fixed /initial
state/ to some /final state/. Any sequence that allows reaching a final state
after consuming all the input is considered /accepted/; hence, making the
automaton a predicate for sequences of inputs. Note that this requires sequences
to be finite, although it is possible to extend the notion to infinite
sequences, it is not useful for most computations as executions must be finite.

#+LATEX: \begin{definition}[Automaton]
Given a Labeled Graph $(Q, T, \Pred{\Sigma}, l)$, where $Q$ is a set of /States/,
$T$ a collection /Transitions/, and $l$ assigns predicates on $\Pred{\Sigma}$
to each transition, we define an /Automaton/ as the tuple
$(Q, T, \Pred{\Sigma}, l, q_0, F)$, where $q_0 \in Q$ is the /starting state/,
and $F\in \Pred{S}$ is a predicate that selects the /final states/.
#+LATEX: \end{definition}

Note that the classical definitions by \citeA{AutomataTheory} distinguish
different kinds of machines. The relation between this Labeled Graph based
definition and Non-deterministic finite automaton is discussed on the appendix.


** Resource Description Framework
The Resource Description Framework, /RDF/, is the building block of the
/Semantic Web/. It standardizes how to publish pieces of a universal graph where
anyone can share and consume data.

RDF requires $3$ disjoint sets to exist, the /IRIs/ $\IRI$, the /Blank Nodes/ $\Blank$,
 and the /Literals/ $\Lit$.
/IRIs/ are special, as they allow to retrieve information from the web by dereferencing. /Blank
 Nodes/ serve as anonymous /IRIs/ that join information, but cannot be
 dereferenced. And finally /Literals/ are information by themselves, such as
 text or dates.

#+LATEX: \begin{definition}[RDF triple]
/RDF triples/ are triples $(s, p, o) \in (\IRI \cup \Blank) \times \IRI \times (\IRI \cup \Blank \cup \Lit)$,
where $s$ is known as the /subject/, $p$ as the predicate, and $o$ as the
/object/.
#+LATEX: \end{definition}
An RDF Triple states that the predicate $p$ holds for the pair of vertices $(s,
o)$ on the graph. Note that predicates *must* be /IRIs/, this is key to
encourage the use of a common vocabulary among all publishers of RDF Triples,
also subjects and objects can be data from different servers, allowing
information to be linked to the original source instead of being duplicated.


** The Semantic Web Graph

The goal of the Semantic Web, is to build a


** Search Problem.
Lorem ipsum.
*** Heuristic Search
# http://stackoverflow.com/questions/29470253/astar-explanation-of-name


* Property Automata
On this chapter we will develop a finite-state machine to accept or reject a labeled path.
** Definition.
*** TODO Property Automata
A /Property Automata/ is an /Automata/ enhanced with additional

** Induced Heuristic.
*** TODO Computing the Heuristic
*** TODO Consistency.
* Search with Property Automata
** Definition.
*** TODO Search algorithm.
*** TODO Definition as a Distributed Algorithm.
  - Advantages over single threaded formulation.
** TODO Multi-point search.
  - Filter invertibility.
** Remarks
Note that the Search with Property Automata can simulate old Automata if the database $(\set{q_0}, \set{(q_0, q_0), \Sigma, l}$ is considered, where $l(q_0) = 2^\Sigma$.
Not only it happens that the paths (words) accepted are the same, but also that given a Query (regular expression), paths (words) can be gathered exhaustively in an ordered way.


* Searching on the Semantic Web
** TODO The Semantic Web Graph.
** TODO Limitations of the Web.
** TODO Search Problem.
** TODO Evaluation.

To test the feasibility of navigating the web through documents


* Conclusions
* TODO Future Work
** Automata
*** Define a Query language.
Currently the definition relies on the existence of adequate filter functions
** Search
*** Multi point search
Notice that starting point can be seen as search node that is /allowed/ by the the starting
by only looking a

** Semantic Web
*** Rewriting SPARQL to Property Automata
SPARQL endpoints can benefit from our approach to answer /Property Path/ queries
in a faster and more reliable way, as currently well known engines either don't
support /Property Paths/ or perform badly while computing answers \cite{BaierDRV16}.

The most outstanding property of our approach, is that incremental answering
allows to compute queries using ~limit~ in without computing all the answers as
currently some /Property Path/ capable endpoints do.

*** Discovery Protocol
On our experiments was necessary to allow querying the SPARQL endpoints to look
for /backward triples/, as documents on some servers only were complete with
respect to triples starting on the queried IRI.

Our approach to avoid navigating only from incomplete documents relied on a
manual matching between IRI prefixes and SPARQL endpoint locations. This manual
matching forbids the use of this trick to explore new servers.

The technique could be used reliably if a standardized way to locate SPARQL
endpoints was available.

*** Local path queries
Using SPARQL endpoints not only allows to retrieve more reliable data, but it
also could enable faster navigation if more expressive queries are allowed, as
simply querying for longer paths would save some roundtrips to the server,
reducing the network load against the server in exchange for some extra server
CPU time that depends on a length parameter.

This approach requires only a subset of SPARQL capabilities, and could be
handled with less powerful servers that can also be allowed to impose a limit on
the length. For this to reduce network traffic, only paths local to the server
can be answered, but partial paths are also useful to the clients.

This approach subsumes the proposal from Triple Pattern Fragments, as they only
consider paths of length 1. Note that servers could also run A* in order to
search their local database while answering, this uniformity suggests that
clients can easily become servers, serving their data and the data gathered
while navigating.

*** Extending documents information
Documents currently give back triples that mention the IRI requested. Following
the goal from local path queries, this can be generalized to paths that start at
the IRI, which would enable to reduce roundtrips if the paths are useful.

This would be a simple way to gain the benefits from Local path queries, but
requires to fix the document to hold more paths, which can affect performance
when the additional information is not useful for the client.

*** Statistics
Collecting statistics about the data served is probably the best way to improve
the layout and connectivity of the data served without requiring any supervision
or expert knowledge.

The /HTTP protocol/ provides the foundation for the Semantic Web, and it already
carries useful metadata for servers as part of the standard \cite{httpHeaders}.
For example, the /referer field/ tracks the IRI used to discover the IRI
currently being dereferenced, so it can be used to let servers exchange and
replicate triples to keep connectivity of reversed links. This replication
*needs* feedback from the users, as a single server simply cannot hold all the
triples mentioning any IRI, therefore, keeping only the top k-th most used
triples becomes a good mechanism to hold important information under reasonable
space constraints.

Serving the most used outgoing IRIs first would enable clients to share hints on
which are the most useful IRIs to explore, allowing clients to minimize the
effort made to get the first answers.

Those are only 2 examples of what can be achieved by using statistics, both by
themselves are promising, so exploring what can be done with additional metadata
is really interesting.


* References                                                        :ignore:
#+begin_export LaTeX
\cleardoublepage
\phantomsection \label{references}
\bibliographystyle{apacite}
\renewcommand{\bibname}{REFERENCES}
\bibliography{thesis}
#+end_export

* Appendix                                                          :ignore:
#+begin_export LaTeX
\appendix % It is like a chapter, so each appendix (A, B, C...) must to be considered as a section
#+end_export
** Automata definitions and their relationship
The classic, /Deterministic Finite Automata/ (/DFA/) definition is by a tuple $(Q,
q_0, \Sigma, \delta, F)$ where $Q$ is a finite set of /States/ and $\delta
\colon Q \times \Sigma \to Q$ is a total function fixing the transitions of the
machine.

Definitions differ on how transitions are stated by using $\delta$ or $(E, l)$
respectively.

A /DFA/ can be transformed into an /Automaton/ by noting that $\delta$ induces
the /edges/ and their /labels/.
A sample mapping given by $\delta$ can be the following, $\delta(u, a) = v$.
This requires that an edge $e\in E$ from $u$ to $v$ exist, and that it's
assigned label is $a$, so $l(e)=a$.

Note that, unlike /DFA/, the /Automaton/ do not need to have transitions defined
for every state and label pair, which makes it closer to a /Non-deterministic
Finite Automaton/ (/NFA/). Again, a similar transformation can be used to turn a
/NFA/ into an /Automaton/.

An /Automaton/ using finite states and without repeating labels between any pair
of states can be turned into a /NFA/. To do so, $\delta$ must be built from $(E, l)$.
Given any edge $e=(u,v)$ on $E$, $\delta$ should map $(u, l(e))$ to the smallest
possible set containing $v$ satisfying this rule for every other edge.


