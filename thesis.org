# #+TITLE: Don't use org-mode title, it inserts unwanted \maketitle
#+AUTHOR: Dietrich Arnaldo Daroch González
#+DATE: December, 2016
#+LANGUAGE: en


# Setup
# -----
# Using LaTeX_CLASS requires additional setup!
#+LaTeX_CLASS: puc
#+LaTeX_CLASS_OPTIONS: [12pt,reqno,oneside]

# Packages
#+LaTeX_HEADER: \input{setup.tex}  % pucthesis setup (should be part of the LaTeX class!
#+LaTeX_HEADER: \usepackage[spanish,english]{babel}

# microtype (xelatex)
#+LaTeX_HEADER: \usepackage[final,factor=1100,stretch=10,shrink=10]{microtype}
# #+LaTeX_HEADER: \usepackage[activate={true,nocompatibility},final,tracking=true,kerning=true,spacing=true,factor=1100,stretch=10,shrink=10]{microtype}


#+SEQ_TODO: TODO | REVIEW DONE

#+OPTIONS: toc:nil
#+OPTIONS: tasks:t
#+OPTIONS: tags:nil
#+OPTIONS: d:nil
#+OPTIONS: skip:nil ^:nil timestamp:nil
#+STARTUP: overview

# Annoyances
# ----------
# „Quotes“

* Header                                                            :ignore:
#+begin_export LaTeX
\title[Evaluating Navigational RDF Queries]{Evaluating Navigational RDF Queries
	over the Web}

\address{Escuela de Ingenier\'ia\\
				 Pontificia Universidad Cat\'olica de Chile\\
				 Vicu\~na Mackenna 4860\\
				 Santiago, Chile\\
				 {\it Tel.\/} : 56 (2) 354-2000}
\email{Dietrich.Daroch@gmail.com}
%
\facultyto    {the School of Engineering}
\department   {}
\faculty      {Faculty of Engineering}
\degree       {Master of Science in Engineering}
\advisor      {Jorge Baier A.}
\committeememberA {Juan L. Reutter D.}
%\committeememberB {Committee Member B (Optional)}
\guestmemberA {Jorge P\'erez R.}
%\guestmemberB {Guest Committee Member B (Optional)}
\ogrsmember   {Juan Siding B.}  % TODO: change
\subject      {Engineering}
\date         {Diciembre 2016}
\copyrightname{Dietrich Daroch}
\copyrightyear{MMXVI}

\dedication {
To everyone
}

\NoChapterPageNumber
\pagenumbering{roman}
\maketitle
#+end_export

* Acknowledgements                                                  :ignore:
#+begin_export LaTeX
\selectlanguage{english}
\chapter*{Acknowledgements}

\cleardoublepage
#+end_export

* Tables                                                            :ignore:
#+begin_export LaTeX
\tableofcontents
\listoftables
\listoffigures
\cleardoublepage % In double-sided printing style makes the next page
#+end_export

* Abstract                                                          :ignore:
#+begin_export LaTeX
\selectlanguage{english}
\chapter*{Abstract}
\label{ch:abstract}
This works presents a novel reduction from \emph{Property Path Computation} to
\emph{Heuristic Search}, which enables to solve queries in a more efficient way
than the previously known reduction to \emph{Uninformed Search}.
The new reduction enables to use years of reaserch on Heuristic Search made by
the Artificial Intelligence community to solve \emph{Property Paths} over
\emph{Linked Data} more efficiently.
Besides the reduction, optimizations and implementation details are reviewed.


% Keywords
\vfill
{\bf Keywords:} \parbox[t]{.75\textwidth}{
	RDF, Semantic Web, Property Paths, Graph Databases
}
#+end_export

#+begin_export LaTeX
\chapter*{Resumen}
\label{ch:resumen}
\selectlanguage{spanish}
Este trabajo presenta una reducción nueva desde \emph{Property Path Computation} a
\emph{Búsqueda Heurística}, la cuál permite resolver consultas de manera más
eficiente que la anteriormente conocida reducción a \emph{Búsqueda Ciega}.
Esta nueva reducción permite aprovechar años de investigación en Búsqueda por
parte de la comunidad de Inteligencia Artificial para resolver consultas sobre
\emph{Property Paths} en \emph{Linked Data} de forma más eficiente.
Además de la reducción, se estudian optimizaciones y detalles de implementación.

% Keywords
\vfill
{\bf Palabras Claves:} \parbox[t]{.75\textwidth}{
	RDF, Web Semántica, Property Paths, Bases de Datos de Grafos
}


\selectlanguage{english}
#+end_export


* Setup                                                             :ignore:
#+begin_export LaTeX
\cleardoublepage
\pagenumbering{arabic}
#+end_export



* TODO Introduction
** TODO Background
 People indirectly uses databases many times a day without noticing it.
 Databases are key to manage information in many systems, which store information
 ranging from instant messaging systems, email and documents to media and banking.
 Today, that information is likely to be stored in tables obeying schemas
 carefully tailored for each application.
 This makes linking data across multiple applications hard, if not impossible.

 To overcome this lack of

 Linking data is not only interesting because it's hard to do, but mostly because
 it offers new data to enhance applications.\cite{BaierDRV16}.

 Today databases are used internally by many applications and systems

 Long ago efforts to understand text were made, but today not all information
 lies on plain text, or tree hierarchies. Techniques and machinery that appeared
 then are not directly useful when working with Graphs.


** TODO Contribution
Essentially this works provides an algorithm to compute /Property Paths/ by
navigating that it's more efficient than the previously existing ones.

The algorithm is accompanied by proof of it's efficiency, as well as an
experimental evaluation that provides explicit evidence along with   the
contribution is


** TODO Outline
Section \ref{sec:Preliminaries} presents some background in Graphs and Automata,
as well as a definitions for the Semantic Web Search Problems, including
Heuristic Search.


* Preliminaries
#+begin_export latex
\label{sec:Preliminaries}
#+end_export

** Graphs.
Intuitively, a Graph is a collection of objects with information about how those objects are related.

*** REVIEW Definition                                                 :def:
CLOSED: [2016-08-06 Sat 18:43]
Given a set $V$, a /Graph/ is a pair /vertices/ and /edges/, $(V, E)$, where $E$
is a collection of elements from $V^2$. $E$ is usually a set, but when it allows
duplication, the /Graph/ is called a /Multi-Graph/ as multiple edges can join
the same pair of vertices.

The relation given by $E$ can be further detailed by using a set of labels $\Sigma$ and
a function $l\colon E \to \Sigma$ that assigns labels to each edge.

With this in mind, we define a /Labeled Graph/ as the tuple $(V, E, \Sigma, l)$.
We say that a Labeled Graph is /self-labeled/ when $\Sigma=V$.

It's easy to find examples that use graphs, for example consider $V$ as a set of
people, and $E$ as arcs that depict relations between the people. To explain
each relation on $E$, the label $\Sigma$ can contain, for example, /friends/,
/best-friends/, /ex-girlfriend/ can be used.

** Automata.
An /Automaton/ is a Labeled Graph extended to describe patterns of labels. The
patterns describes are the labels of a path starting from a fixed vertex that
end on selected vertices.
Note that the classical definition by definition by \citeA{AutomataTheory} is
more strict, as it implicitly imposes restrictions on the graph. The relation
between both definitions is discussed on the appendix.

*** TODO Definition                                                 :def:
Given a Labeled Graph $(S, T, \Sigma, l)$, where $S$ is a set of /States/, and
$T$ a collection /Transitions/, an /Automaton/, is the tuple $(S, T, \Sigma, l,
s_0, F)$, where $s_0 \in S$ is the /starting state/, and $F \subset S$ is the
set of /final states/.



** Semantic Web

** Search Problem.
Lorem ipsum.
*** Heuristic Search

* Property Automata
On this chapter we will develop a finite-state machine to accept or reject a labeled path.
** Definition.
*** TODO Filters
*** TODO Automata
** Induced Heuristic.
*** TODO Computing the Heuristic
*** TODO Consistency.
* Search with Property Automata
** Definition.
*** TODO Search algorithm.
*** TODO Definition as a Distributed Algorithm.
  - Advantages over single threaded formulation.
** TODO Multi-point search.
  - Filter invertibility.
** Remarks
Note that the Search with Property Automata can simulate old Automata if the database $(\set{s_0}, \set{(s_0, s_0), \Sigma, l}$ is considered, where $l(s_0) = 2^\Sigma$.
Not only it happens that the paths (words) accepted are the same, but also that given a Query (regular expression), paths (words) can be gathered exhaustively in an ordered way.
* Searching on the Semantic Web
** TODO The Semantic Web Graph.
** TODO Limitations of the Web.
** TODO Search Problem.
** TODO Evaluation.
* Conclusions
* TODO Future Work
** Automata
*** Define a Query language.
Currently the definition relies on the existence of adequate filter functions
** Search
*** Multi point search
Notice that starting point can be seen as search node that is /allowed/ by the the starting
by only looking a

** Semantic Web
*** Rewriting SPARQL to Property Automata
SPARQL endpoints can benefit from our approach to answer /Property Path/ queries
in a faster and more reliable way, as currently well known engines either don't
support /Property Paths/ or perform badly while computing answers \cite{BaierDRV16}.

The most outstanding property of our approach, is that incremental answering
allows to compute queries using ~limit~ in without computing all the answers as
currently some /Property Path/ capable endpoints do.

*** Discovery Protocol
On our experiments was necessary to allow querying the SPARQL endpoints to look
for /backward triples/, as documents on some servers only were complete with
respect to triples starting on the queried IRI.

Our approach to avoid navigating only from incomplete documents relied on a
manual matching between IRI prefixes and SPARQL endpoint locations. This manual
matching forbids the use of this trick to explore new servers.

The technique could be used reliably if a standardized way to locate SPARQL
endpoints was available.

*** Local path queries
Using SPARQL endpoints not only allows to retrieve more reliable data, but it
also could enable faster navigation if more expressive queries are allowed, as
simply querying for longer paths would save some roundtrips to the server,
reducing the network load against the server in exchange for some extra server
CPU time that depends on a length parameter.

This approach requires only a subset of SPARQL capabilities, and could be
handled with less powerful servers that can also be allowed to impose a limit on
the length. For this to reduce network traffic, only paths local to the server
can be answered, but partial paths are also useful to the clients.

This approach subsumes the proposal from Triple Pattern Fragments, as they only
consider paths of length 1. Note that servers could also run A* in order to
search their local database while answering, this uniformity suggests that
clients can easily become servers, serving their data and the data gathered
while navigating.

*** Extending documents information
Documents currently give back triples that mention the IRI requested. Following
the goal from local path queries, this can be generalized to paths that start at
the IRI, which would enable to reduce roundtrips if the paths are useful.

This would be a simple way to gain the benefits from Local path queries, but
requires to fix the document to hold more paths, which can affect performance
when the additional information is not useful for the client.

*** Statistics
Collecting statistics about the data served is probably the best way to improve
the layout and connectivity of the data served without requiring any supervision
or expert knowledge.

The /HTTP protocol/ provides the foundation for the Semantic Web, and it already
carries useful metadata for servers as part of the standard \cite{httpHeaders}.
For example, the /referer field/ tracks the IRI used to discover the IRI
currently being dereferenced, so it can be used to let servers exchange and
replicate triples to keep connectivity of reversed links. This replication
*needs* feedback from the users, as a single server simply cannot hold all the
triples mentioning any IRI, therefore, keeping only the top k-th most used
triples becomes a good mechanism to hold important information under reasonable
space constraints.

Serving the most used outgoing IRIs first would enable clients to share hints on
which are the most useful IRIs to explore, allowing clients to minimize the
effort made to get the first answers.

Those are only 2 examples of what can be achieved by using statistics, both by
themselves are promising, so exploring what can be done with additional metadata
is really interesting.


* References                                                        :ignore:
#+begin_export LaTeX
\cleardoublepage
\phantomsection \label{references}
\bibliographystyle{apacite}
\renewcommand{\bibname}{REFERENCES}
\bibliography{thesis}
#+end_export

* Appendix                                                          :ignore:
#+begin_export LaTeX
\appendix % It is like a chapter, so each appendix (A, B, C...) must to be considered as a section
#+end_export
** Classic Automata and the Labeled Graph based definition
The classic, /Deterministic Finite Automata/ (/DFA/) definition is by a tuple $(Q,
q_0, \Sigma, \delta, F)$ where $Q$ is a finite set of /States/ and $\delta
\colon Q \times \Sigma \to Q$ is a total function fixing the transitions of the
machine.

Definitions differ on how transitions are stated by using $\delta$ or $(E, l)$
respectively.

A /DFA/ can be transformed into an /Automaton/ by noting that $\delta$ induces
the /edges/ and their /labels/.
A sample mapping given by $\delta$ can be the following, $\delta(u, a) = v$.
This requires that an edge $e\in E$ from $u$ to $v$ exist, and that it's assigned label is $a$, so $l(e)=a$.

Note that /Automaton/ do not need to have transitions defined for every state
and label pair, which makes it closer to a /Non-deterministic Finite Automaton/
(/NFA/) (without empty transitions). Again, a similar transformation can be used
to turn a /NFA/ into an /Automaton/.

An /Automaton/ using finite states and without repeating labels between any pair
of states can be turned into a /NFA/. To do so, $\delta$ must be built from $(E, l)$.
Given any edge $e=(u,v)$ on $E$, $\delta$ should map $(u, l(e))$ to the smallest
possible set containing $v$ satisfying this rule for every other edge.
